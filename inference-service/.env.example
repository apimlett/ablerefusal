# Inference Service Configuration

# Server settings
HOST=0.0.0.0
PORT=8001
ENV=development

# Model settings
MODELS_DIR=./models
OUTPUTS_DIR=./outputs
DEFAULT_MODEL=runwayml/stable-diffusion-v1-5

# Device settings (cuda, cpu, mps for Mac)
DEVICE=cuda

# Performance settings
ENABLE_XFORMERS=true
ENABLE_CPU_OFFLOAD=false

# Cache settings
CACHE_DIR=~/.cache/huggingface

# Redis settings (optional, for production)
# REDIS_HOST=localhost
# REDIS_PORT=6379
# REDIS_DB=0